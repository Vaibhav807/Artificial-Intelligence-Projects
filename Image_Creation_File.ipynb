{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNMLJhjZ9fUTo/ot4JbsrCq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vaibhav807/Artificial-Intelligence-Projects/blob/main/Image_Creation_File.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final**"
      ],
      "metadata": {
        "id": "oYUJZKvLlINX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip enose_dataset.zip"
      ],
      "metadata": {
        "id": "Wr5DJqSUffiB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a20c530-495d-40be-963a-a1488ea10b0d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  enose_dataset.zip\n",
            "   creating: dataset/\n",
            "  inflating: dataset/submission_example.csv  \n",
            "  inflating: dataset/.DS_Store       \n",
            "  inflating: __MACOSX/dataset/._.DS_Store  \n",
            "   creating: dataset/test/\n",
            "   creating: dataset/train/\n",
            "  inflating: dataset/train_test_split_order.csv  \n",
            "  inflating: __MACOSX/dataset/._train_test_split_order.csv  \n",
            "  inflating: dataset/test/NTL E-Nose - Patient 34.txt  \n",
            "  inflating: __MACOSX/dataset/test/._NTL E-Nose - Patient 34.txt  \n",
            "  inflating: dataset/test/NTL E-Nose - Patient 23.txt  \n",
            "  inflating: __MACOSX/dataset/test/._NTL E-Nose - Patient 23.txt  \n",
            "  inflating: dataset/test/NTL E-Nose - Patient 33.txt  \n",
            "  inflating: __MACOSX/dataset/test/._NTL E-Nose - Patient 33.txt  \n",
            "  inflating: dataset/test/NTL E-Nose - Patient 32.txt  \n",
            "  inflating: __MACOSX/dataset/test/._NTL E-Nose - Patient 32.txt  \n",
            "  inflating: dataset/test/NTL E-Nose - Patient 24.txt  \n",
            "  inflating: __MACOSX/dataset/test/._NTL E-Nose - Patient 24.txt  \n",
            "  inflating: dataset/test/NTL E-Nose - Patient 25.txt  \n",
            "  inflating: __MACOSX/dataset/test/._NTL E-Nose - Patient 25.txt  \n",
            "  inflating: dataset/test/NTL E-Nose - Patient 43.txt  \n",
            "  inflating: __MACOSX/dataset/test/._NTL E-Nose - Patient 43.txt  \n",
            "  inflating: dataset/test/NTL E-Nose - Patient 54.txt  \n",
            "  inflating: __MACOSX/dataset/test/._NTL E-Nose - Patient 54.txt  \n",
            "  inflating: dataset/test/NTL E-Nose - Patient 51.txt  \n",
            "  inflating: __MACOSX/dataset/test/._NTL E-Nose - Patient 51.txt  \n",
            "  inflating: dataset/test/NTL E-Nose - Patient 52.txt  \n",
            "  inflating: __MACOSX/dataset/test/._NTL E-Nose - Patient 52.txt  \n",
            "  inflating: dataset/test/NTL E-Nose - Patient 48.txt  \n",
            "  inflating: __MACOSX/dataset/test/._NTL E-Nose - Patient 48.txt  \n",
            "  inflating: dataset/test/NTL E-Nose - Patient 49.txt  \n",
            "  inflating: __MACOSX/dataset/test/._NTL E-Nose - Patient 49.txt  \n",
            "  inflating: dataset/test/NTL E-Nose - Patient 59.txt  \n",
            "  inflating: __MACOSX/dataset/test/._NTL E-Nose - Patient 59.txt  \n",
            "  inflating: dataset/test/NTL E-Nose - Patient 2.txt  \n",
            "  inflating: __MACOSX/dataset/test/._NTL E-Nose - Patient 2.txt  \n",
            "  inflating: dataset/test/NTL E-Nose - Patient 3.txt  \n",
            "  inflating: __MACOSX/dataset/test/._NTL E-Nose - Patient 3.txt  \n",
            "  inflating: dataset/test/NTL E-Nose - Patient 14.txt  \n",
            "  inflating: __MACOSX/dataset/test/._NTL E-Nose - Patient 14.txt  \n",
            "  inflating: dataset/test/NTL E-Nose - Patient 15.txt  \n",
            "  inflating: __MACOSX/dataset/test/._NTL E-Nose - Patient 15.txt  \n",
            "  inflating: dataset/test/NTL E-Nose - Patient 11.txt  \n",
            "  inflating: __MACOSX/dataset/test/._NTL E-Nose - Patient 11.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 21.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 21.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 35.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 35.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 20.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 20.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 36.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 36.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 22.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 22.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 37.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 37.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 27.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 27.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 26.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 26.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 18.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 18.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 30.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 30.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 31.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 31.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 19.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 19.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 42.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 42.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 56.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 56.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 57.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 57.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 55.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 55.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 41.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 41.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 40.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 40.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 8.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 8.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 50.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 50.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 44.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 44.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 45.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 45.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 9.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 9.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 47.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 47.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 53.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 53.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 46.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 46.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 7.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 7.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 63.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 63.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 62.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 62.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 6.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 6.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 4.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 4.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 60.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 60.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 61.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 61.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 5.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 5.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 1.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 1.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 58.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 58.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 28.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 28.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 29.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 29.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 17.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 17.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 16.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 16.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 12.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 12.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 13.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 13.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 39.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 39.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 10.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 10.txt  \n",
            "  inflating: dataset/train/NTL E-Nose - Patient 38.txt  \n",
            "  inflating: __MACOSX/dataset/train/._NTL E-Nose - Patient 38.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def convert_time_to_seconds(time_str):\n",
        "    minutes, seconds = map(float, time_str.split(':'))\n",
        "    return minutes * 60 + seconds\n",
        "\n",
        "def process_file(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    id_line = lines[0].strip()\n",
        "    result_line = lines[1].strip()\n",
        "\n",
        "    id_value = int(id_line.split(':')[1].strip())\n",
        "    result_value = result_line.split(':')[1].strip()\n",
        "\n",
        "    # Remove the ID, Result lines and the whitespace line, and the header line\n",
        "    cleaned_lines = lines[4:]\n",
        "\n",
        "    # Convert the time values and store the numerical data\n",
        "    data = []\n",
        "    cumulative_time = 0\n",
        "    previous_time_value = convert_time_to_seconds(cleaned_lines[0].strip().split('\\t')[0])  # Initialize with the first time value\n",
        "\n",
        "    for i, line in enumerate(cleaned_lines):\n",
        "        parts = line.strip().split('\\t')\n",
        "        current_time_value = convert_time_to_seconds(parts[0])\n",
        "\n",
        "        if i == 0:\n",
        "            time_in_seconds = 0\n",
        "        else:\n",
        "            if current_time_value < previous_time_value:\n",
        "                # Handle clock reset by finding the absolute difference and subtracting 3600\n",
        "                time_in_seconds = abs(current_time_value - previous_time_value) - 3600\n",
        "            else:\n",
        "                time_in_seconds = current_time_value - previous_time_value\n",
        "\n",
        "        cumulative_time += time_in_seconds\n",
        "        previous_time_value = current_time_value\n",
        "        numerical_values = list(map(float, parts[1:]))\n",
        "        data.append([cumulative_time] + numerical_values)\n",
        "\n",
        "    # Create DataFrame for standardization\n",
        "    df = pd.DataFrame(data)\n",
        "    df.iloc[:, 1:] = df.iloc[:, 1:].apply(lambda x: (x - x.mean()) / x.std())\n",
        "    numerical_data = df.values.tolist()\n",
        "\n",
        "    return id_value, result_value, numerical_data\n"
      ],
      "metadata": {
        "id": "_ozPqHhoxMk-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_directory(directory_path):\n",
        "    positive_ids = []\n",
        "    positive_results = []\n",
        "    positive_data = []\n",
        "\n",
        "    negative_ids = []\n",
        "    negative_results = []\n",
        "    negative_data = []\n",
        "\n",
        "    for file_name in os.listdir(directory_path):\n",
        "        file_path = os.path.join(directory_path, file_name)\n",
        "        id_value, result_value, numerical_data = process_file(file_path)\n",
        "        if result_value.upper() == \"POSITIVE\":\n",
        "            positive_ids.append(id_value)\n",
        "            positive_results.append(result_value)\n",
        "            positive_data.append(numerical_data)\n",
        "        else:\n",
        "            negative_ids.append(id_value)\n",
        "            negative_results.append(result_value)\n",
        "            negative_data.append(numerical_data)\n",
        "\n",
        "    return positive_ids, positive_results, positive_data, negative_ids, negative_results, negative_data"
      ],
      "metadata": {
        "id": "NOERprDmxPWS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_by_id(file_id, positive_ids, positive_data, negative_ids, negative_data):\n",
        "    if file_id in positive_ids:\n",
        "        index = positive_ids.index(file_id)\n",
        "        return positive_data[index]\n",
        "    elif file_id in negative_ids:\n",
        "        index = negative_ids.index(file_id)\n",
        "        return negative_data[index]\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "QbpmuxzExNvL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_data(data_for_id, file_id, cases):\n",
        "    print(f\"WORKING ON {file_id} GRAPH\")\n",
        "    time_values = [row[0] for row in data_for_id]\n",
        "    data_matrix = [row[1:] for row in data_for_id]\n",
        "    data_matrix = list(zip(*data_matrix))  # Transpose the matrix to get columns\n",
        "\n",
        "    # Identify the first point where cumulative time reaches the specified thresholds\n",
        "    thresholds = [300, 360, 480, 540, 660, 720, 840]\n",
        "    threshold_colors = {300: 'black', 360: 'blue', 480: 'red', 540: 'blue', 660: 'red', 720: 'blue', 840: 'blue'}\n",
        "    threshold_lines = {}\n",
        "\n",
        "    for time in time_values:\n",
        "        for threshold in thresholds:\n",
        "            if threshold not in threshold_lines and time >= threshold:\n",
        "                threshold_lines[threshold] = time\n",
        "\n",
        "    fig, axes = plt.subplots(8, 8, figsize=(20, 20))\n",
        "\n",
        "    # Add a big title at the top\n",
        "    fig.suptitle(f'ID {file_id} - {cases}', fontsize=20)\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.plot(time_values, data_matrix[i])\n",
        "        for threshold, time in threshold_lines.items():\n",
        "            ax.axvline(x=time, color=threshold_colors[threshold], linestyle='--', linewidth=0.8)\n",
        "        ax.set_title(f'D{i+1}', fontsize=10)\n",
        "        ax.set_xlabel('Time (s)', fontsize=8)\n",
        "        ax.set_ylabel('Value', fontsize=8)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust the rect to leave space for the suptitle\n",
        "\n",
        "    # Save the plot to a file\n",
        "    plt.savefig(f'{file_id}_Graph.png')\n",
        "    plt.close(fig)\n"
      ],
      "metadata": {
        "id": "9bEe3jSk2o0t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Define the path to the directory\n",
        "directory_path = '/content/dataset/train'\n",
        "\n",
        "positive_ids, positive_results, positive_data, negative_ids, negative_results, negative_data = process_directory(directory_path)\n",
        "\n",
        "# Print out the IDs for positive cases as a list\n",
        "print(\"Positive Case IDs:\")\n",
        "print(positive_ids)\n",
        "\n",
        "# Print out the IDs for negative cases as a list\n",
        "print(\"\\nNegative Case IDs:\")\n",
        "print(negative_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS9knNBaxRI4",
        "outputId": "e470cda3-e937-4020-b7bb-8bd1db8e2d57"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive Case IDs:\n",
            "[35, 29, 30, 22, 45, 31, 63, 38, 21, 1, 44, 28, 40, 60, 61, 12, 36, 13, 47]\n",
            "\n",
            "Negative Case IDs:\n",
            "[5, 6, 20, 53, 16, 17, 7, 41, 55, 10, 46, 18, 27, 26, 4, 62, 42, 39, 50, 58, 19, 8, 57, 56, 37, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file_id_to_search in negative_ids:\n",
        "    data_for_id = get_data_by_id(file_id_to_search, positive_ids, positive_data, negative_ids, negative_data)\n",
        "\n",
        "    if data_for_id:\n",
        "        plot_data(data_for_id, file_id_to_search, \"NEGATIVE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1R0kZFZ6Qni",
        "outputId": "72b20852-4023-473a-994d-07ea3be126a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WORKING ON 5 GRAPH\n",
            "WORKING ON 6 GRAPH\n",
            "WORKING ON 20 GRAPH\n",
            "WORKING ON 53 GRAPH\n",
            "WORKING ON 16 GRAPH\n",
            "WORKING ON 17 GRAPH\n",
            "WORKING ON 7 GRAPH\n",
            "WORKING ON 41 GRAPH\n",
            "WORKING ON 55 GRAPH\n",
            "WORKING ON 10 GRAPH\n",
            "WORKING ON 46 GRAPH\n",
            "WORKING ON 18 GRAPH\n",
            "WORKING ON 27 GRAPH\n",
            "WORKING ON 26 GRAPH\n",
            "WORKING ON 4 GRAPH\n",
            "WORKING ON 62 GRAPH\n",
            "WORKING ON 42 GRAPH\n",
            "WORKING ON 39 GRAPH\n",
            "WORKING ON 50 GRAPH\n",
            "WORKING ON 58 GRAPH\n",
            "WORKING ON 19 GRAPH\n",
            "WORKING ON 8 GRAPH\n",
            "WORKING ON 57 GRAPH\n",
            "WORKING ON 56 GRAPH\n",
            "WORKING ON 37 GRAPH\n",
            "WORKING ON 9 GRAPH\n"
          ]
        }
      ]
    }
  ]
}